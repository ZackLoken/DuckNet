{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(self, destination):\n",
    "    from torch import package\n",
    "\n",
    "    #internal modules\n",
    "    MODULES = ['datasets', 'traininglib']\n",
    "    \n",
    "    if isinstance(destination, str):\n",
    "        destination = time.strftime(destination)\n",
    "        if not destination.endswith('.pt.zip'):\n",
    "            destination += '.pt.zip'\n",
    "\n",
    "    with package.PackageExporter(destination) as exp:\n",
    "        interns = [__name__.split('.')[-1]]+MODULES\n",
    "        exp.intern(interns)\n",
    "        exp.extern('**', exclude=['torchvision.**'])\n",
    "        externs = ['torchvision.ops.**', 'torchvision.datasets.**', 'torchvision.io.**']\n",
    "        exp.intern('torchvision.**', exclude=externs)\n",
    "        exp.extern(externs)\n",
    "        exp.intern('torchvision.models.detection.**')\n",
    "        # force inclusion of internal modules + re-save if importlib.reload'ed\n",
    "        for m in MODULES:\n",
    "            exp.save_module(m, dependencies=True)\n",
    "        exp.save_module('modellib', dependencies=True)\n",
    "        exp.save_pickle('model', 'model.pkl', self)\n",
    "        exp.save_text('model', 'class_list.txt', '\\n'.join(self.class_list))\n",
    "    return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modellib import DuckDetector\n",
    "model = DuckDetector(classes_of_interest=[ # class order must match the label_dict from training\n",
    "                                    'AMCO', 'GADW', 'GWTE', 'MALL', 'NOPI', 'NSHO', 'REDH', 'RNDU'])\n",
    "\n",
    "basemodel_pt_zip = save(self=model, destination=\"basemodel.pt.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "─── basemodel.pt.zip\n",
      "    ├── .data\n",
      "    │   ├── 0.storage\n",
      "    │   ├── 1.storage\n",
      "    │   ├── 10.storage\n",
      "    │   ├── 11.storage\n",
      "    │   ├── 12.storage\n",
      "    │   ├── 13.storage\n",
      "    │   ├── 14.storage\n",
      "    │   ├── 15.storage\n",
      "    │   ├── 16.storage\n",
      "    │   ├── 17.storage\n",
      "    │   ├── 18.storage\n",
      "    │   ├── 19.storage\n",
      "    │   ├── 2.storage\n",
      "    │   ├── 20.storage\n",
      "    │   ├── 21.storage\n",
      "    │   ├── 22.storage\n",
      "    │   ├── 23.storage\n",
      "    │   ├── 24.storage\n",
      "    │   ├── 25.storage\n",
      "    │   ├── 26.storage\n",
      "    │   ├── 27.storage\n",
      "    │   ├── 28.storage\n",
      "    │   ├── 29.storage\n",
      "    │   ├── 3.storage\n",
      "    │   ├── 30.storage\n",
      "    │   ├── 31.storage\n",
      "    │   ├── 32.storage\n",
      "    │   ├── 33.storage\n",
      "    │   ├── 34.storage\n",
      "    │   ├── 35.storage\n",
      "    │   ├── 36.storage\n",
      "    │   ├── 37.storage\n",
      "    │   ├── 38.storage\n",
      "    │   ├── 39.storage\n",
      "    │   ├── 4.storage\n",
      "    │   ├── 40.storage\n",
      "    │   ├── 41.storage\n",
      "    │   ├── 42.storage\n",
      "    │   ├── 43.storage\n",
      "    │   ├── 44.storage\n",
      "    │   ├── 45.storage\n",
      "    │   ├── 46.storage\n",
      "    │   ├── 47.storage\n",
      "    │   ├── 48.storage\n",
      "    │   ├── 49.storage\n",
      "    │   ├── 5.storage\n",
      "    │   ├── 50.storage\n",
      "    │   ├── 51.storage\n",
      "    │   ├── 52.storage\n",
      "    │   ├── 53.storage\n",
      "    │   ├── 54.storage\n",
      "    │   ├── 55.storage\n",
      "    │   ├── 56.storage\n",
      "    │   ├── 57.storage\n",
      "    │   ├── 58.storage\n",
      "    │   ├── 59.storage\n",
      "    │   ├── 6.storage\n",
      "    │   ├── 60.storage\n",
      "    │   ├── 61.storage\n",
      "    │   ├── 62.storage\n",
      "    │   ├── 63.storage\n",
      "    │   ├── 64.storage\n",
      "    │   ├── 65.storage\n",
      "    │   ├── 66.storage\n",
      "    │   ├── 67.storage\n",
      "    │   ├── 68.storage\n",
      "    │   ├── 69.storage\n",
      "    │   ├── 7.storage\n",
      "    │   ├── 70.storage\n",
      "    │   ├── 71.storage\n",
      "    │   ├── 72.storage\n",
      "    │   ├── 73.storage\n",
      "    │   ├── 74.storage\n",
      "    │   ├── 75.storage\n",
      "    │   ├── 76.storage\n",
      "    │   ├── 77.storage\n",
      "    │   ├── 78.storage\n",
      "    │   ├── 8.storage\n",
      "    │   ├── 9.storage\n",
      "    │   ├── extern_modules\n",
      "    │   ├── python_version\n",
      "    │   └── version\n",
      "    ├── model\n",
      "    │   ├── class_list.txt\n",
      "    │   └── model.pkl\n",
      "    ├── torchvision\n",
      "    │   ├── datapoints\n",
      "    │   │   ├── __init__.py\n",
      "    │   │   ├── _bounding_box.py\n",
      "    │   │   ├── _datapoint.py\n",
      "    │   │   ├── _image.py\n",
      "    │   │   ├── _mask.py\n",
      "    │   │   └── _video.py\n",
      "    │   ├── models\n",
      "    │   │   ├── detection\n",
      "    │   │   │   ├── __init__.py\n",
      "    │   │   │   ├── _utils.py\n",
      "    │   │   │   ├── anchor_utils.py\n",
      "    │   │   │   ├── backbone_utils.py\n",
      "    │   │   │   ├── faster_rcnn.py\n",
      "    │   │   │   ├── fcos.py\n",
      "    │   │   │   ├── generalized_rcnn.py\n",
      "    │   │   │   ├── image_list.py\n",
      "    │   │   │   ├── keypoint_rcnn.py\n",
      "    │   │   │   ├── mask_rcnn.py\n",
      "    │   │   │   ├── retinanet.py\n",
      "    │   │   │   ├── roi_heads.py\n",
      "    │   │   │   ├── rpn.py\n",
      "    │   │   │   ├── ssd.py\n",
      "    │   │   │   ├── ssdlite.py\n",
      "    │   │   │   └── transform.py\n",
      "    │   │   ├── optical_flow\n",
      "    │   │   │   ├── __init__.py\n",
      "    │   │   │   ├── _utils.py\n",
      "    │   │   │   └── raft.py\n",
      "    │   │   ├── quantization\n",
      "    │   │   │   ├── __init__.py\n",
      "    │   │   │   ├── googlenet.py\n",
      "    │   │   │   ├── inception.py\n",
      "    │   │   │   ├── mobilenet.py\n",
      "    │   │   │   ├── mobilenetv2.py\n",
      "    │   │   │   ├── mobilenetv3.py\n",
      "    │   │   │   ├── resnet.py\n",
      "    │   │   │   ├── shufflenetv2.py\n",
      "    │   │   │   └── utils.py\n",
      "    │   │   ├── segmentation\n",
      "    │   │   │   ├── __init__.py\n",
      "    │   │   │   ├── _utils.py\n",
      "    │   │   │   ├── deeplabv3.py\n",
      "    │   │   │   ├── fcn.py\n",
      "    │   │   │   └── lraspp.py\n",
      "    │   │   ├── video\n",
      "    │   │   │   ├── __init__.py\n",
      "    │   │   │   ├── mvit.py\n",
      "    │   │   │   ├── resnet.py\n",
      "    │   │   │   ├── s3d.py\n",
      "    │   │   │   └── swin_transformer.py\n",
      "    │   │   ├── __init__.py\n",
      "    │   │   ├── _api.py\n",
      "    │   │   ├── _meta.py\n",
      "    │   │   ├── _utils.py\n",
      "    │   │   ├── alexnet.py\n",
      "    │   │   ├── convnext.py\n",
      "    │   │   ├── densenet.py\n",
      "    │   │   ├── efficientnet.py\n",
      "    │   │   ├── googlenet.py\n",
      "    │   │   ├── inception.py\n",
      "    │   │   ├── maxvit.py\n",
      "    │   │   ├── mnasnet.py\n",
      "    │   │   ├── mobilenet.py\n",
      "    │   │   ├── mobilenetv2.py\n",
      "    │   │   ├── mobilenetv3.py\n",
      "    │   │   ├── regnet.py\n",
      "    │   │   ├── resnet.py\n",
      "    │   │   ├── shufflenetv2.py\n",
      "    │   │   ├── squeezenet.py\n",
      "    │   │   ├── swin_transformer.py\n",
      "    │   │   ├── vgg.py\n",
      "    │   │   └── vision_transformer.py\n",
      "    │   ├── transforms\n",
      "    │   │   ├── v2\n",
      "    │   │   │   ├── functional\n",
      "    │   │   │   │   ├── __init__.py\n",
      "    │   │   │   │   ├── _augment.py\n",
      "    │   │   │   │   ├── _color.py\n",
      "    │   │   │   │   ├── _deprecated.py\n",
      "    │   │   │   │   ├── _geometry.py\n",
      "    │   │   │   │   ├── _meta.py\n",
      "    │   │   │   │   ├── _misc.py\n",
      "    │   │   │   │   ├── _temporal.py\n",
      "    │   │   │   │   ├── _type_conversion.py\n",
      "    │   │   │   │   └── _utils.py\n",
      "    │   │   │   ├── __init__.py\n",
      "    │   │   │   ├── _augment.py\n",
      "    │   │   │   ├── _auto_augment.py\n",
      "    │   │   │   ├── _color.py\n",
      "    │   │   │   ├── _container.py\n",
      "    │   │   │   ├── _deprecated.py\n",
      "    │   │   │   ├── _geometry.py\n",
      "    │   │   │   ├── _meta.py\n",
      "    │   │   │   ├── _misc.py\n",
      "    │   │   │   ├── _temporal.py\n",
      "    │   │   │   ├── _transform.py\n",
      "    │   │   │   ├── _type_conversion.py\n",
      "    │   │   │   ├── _utils.py\n",
      "    │   │   │   └── utils.py\n",
      "    │   │   ├── __init__.py\n",
      "    │   │   ├── _functional_pil.py\n",
      "    │   │   ├── _functional_tensor.py\n",
      "    │   │   ├── _presets.py\n",
      "    │   │   ├── autoaugment.py\n",
      "    │   │   ├── functional.py\n",
      "    │   │   └── transforms.py\n",
      "    │   ├── __init__.py\n",
      "    │   ├── _internally_replaced_utils.py\n",
      "    │   ├── _utils.py\n",
      "    │   ├── extension.py\n",
      "    │   ├── utils.py\n",
      "    │   └── version.py\n",
      "    ├── datasets.py\n",
      "    ├── modellib.py\n",
      "    └── traininglib.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imp = torch.package.PackageImporter(basemodel_pt_zip)\n",
    "print(imp.file_structure())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Test that packaged model opens</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_path:str, model_name:str) -> \"torch.nn.Module\":\n",
    "            return torch.package.PackageImporter(file_path).load_pickle(model_name, f'{model_name}.pkl', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DuckDetector(\n",
       "  (detector): Detector(\n",
       "    (basemodel): SSD(\n",
       "      (backbone): SSDFeatureExtractorVGG(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (6): ReLU(inplace=True)\n",
       "          (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (8): ReLU(inplace=True)\n",
       "          (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (11): ReLU(inplace=True)\n",
       "          (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (13): ReLU(inplace=True)\n",
       "          (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (15): ReLU(inplace=True)\n",
       "          (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "          (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (18): ReLU(inplace=True)\n",
       "          (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (20): ReLU(inplace=True)\n",
       "          (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (22): ReLU(inplace=True)\n",
       "        )\n",
       "        (extra): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (6): ReLU(inplace=True)\n",
       "            (7): Sequential(\n",
       "              (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "              (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (4): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (3): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (3): ReLU(inplace=True)\n",
       "          )\n",
       "          (3-4): 2 x Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "            (3): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "      (head): SSDHead(\n",
       "        (classification_head): SSDClassificationHead(\n",
       "          (module_list): ModuleList(\n",
       "            (0): Conv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): Conv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): Conv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): Conv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4-5): 2 x Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (regression_head): SSDRegressionHead(\n",
       "          (module_list): ModuleList(\n",
       "            (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (transform): GeneralizedRCNNTransform(\n",
       "          Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "          Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(file_path='basemodel.pt.zip', model_name='model')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Process sample images </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMCO', 'GADW', 'GWTE', 'MALL', 'NOPI', 'NSHO', 'REDH', 'RNDU']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output {'boxes': tensor([[ 68.5479, 184.3041,  90.7941, 207.2784],\n",
      "        [ 70.2120, 281.0377,  93.8413, 298.3578],\n",
      "        [103.5943,  68.6801, 122.8241,  94.4029],\n",
      "        [138.0472, 137.7994, 156.6600, 165.6302],\n",
      "        [202.8893,  57.3380, 219.7253,  85.4486],\n",
      "        [  5.7140, 167.2711,  29.8765, 190.3628],\n",
      "        [  5.7140, 167.2711,  29.8765, 190.3628],\n",
      "        [ 67.5346, 183.5834,  90.3303, 208.0754],\n",
      "        [137.7279, 138.0132, 156.7391, 165.6858],\n",
      "        [103.1496,  69.0710, 123.3665,  94.2176],\n",
      "        [202.9565,  57.7597, 219.5202,  85.8412],\n",
      "        [ 70.2120, 281.0377,  93.8413, 298.3578],\n",
      "        [103.5943,  68.6801, 122.8241,  94.4029],\n",
      "        [138.0472, 137.7994, 156.6600, 165.6302],\n",
      "        [ 70.0272, 281.0748,  94.3444, 298.6465],\n",
      "        [  4.2455, 166.5855,  30.7530, 190.2510],\n",
      "        [202.9565,  57.7597, 219.5202,  85.8412],\n",
      "        [137.7279, 138.0132, 156.7391, 165.6858],\n",
      "        [202.9565,  57.7597, 219.5202,  85.8412],\n",
      "        [  4.2455, 166.5855,  30.7530, 190.2510],\n",
      "        [103.1496,  69.0710, 123.3665,  94.2176],\n",
      "        [203.1626,  57.2917, 219.4591,  85.3568],\n",
      "        [137.7279, 138.0132, 156.7391, 165.6858],\n",
      "        [103.5943,  68.6801, 122.8241,  94.4029],\n",
      "        [ 70.0272, 281.0748,  94.3444, 298.6465],\n",
      "        [ 68.5479, 184.3041,  90.7941, 207.2784],\n",
      "        [203.1626,  57.2917, 219.4591,  85.3568],\n",
      "        [ 73.4526, 290.0251,  93.0984, 300.0000],\n",
      "        [137.9984, 137.9919, 156.9522, 165.1688],\n",
      "        [ 68.5479, 184.3041,  90.7941, 207.2784],\n",
      "        [ 68.3480, 184.3155,  90.3014, 207.0175],\n",
      "        [  5.3363, 166.6185,  30.9511, 190.6335],\n",
      "        [ 70.2120, 281.0377,  93.8413, 298.3578],\n",
      "        [103.1496,  69.0710, 123.3665,  94.2176],\n",
      "        [  4.2455, 166.5855,  30.7530, 190.2510],\n",
      "        [  5.3363, 166.6185,  30.9511, 190.6335],\n",
      "        [ 73.4526, 290.0251,  93.0984, 300.0000],\n",
      "        [158.2388, 239.7198, 161.7242, 243.0724],\n",
      "        [ 69.3950, 289.0555,  83.6577, 300.0000],\n",
      "        [202.9565,  57.7597, 219.5202,  85.8412],\n",
      "        [138.0243, 137.4126, 156.6864, 166.0982]]), 'scores': tensor([0.6714, 0.6266, 0.6104, 0.6097, 0.6094, 0.5449, 0.2199, 0.1845, 0.1319,\n",
      "        0.1134, 0.1112, 0.1092, 0.0994, 0.0857, 0.0766, 0.0719, 0.0708, 0.0661,\n",
      "        0.0638, 0.0618, 0.0602, 0.0586, 0.0583, 0.0503, 0.0482, 0.0461, 0.0427,\n",
      "        0.0378, 0.0305, 0.0304, 0.0270, 0.0258, 0.0212, 0.0206, 0.0190, 0.0185,\n",
      "        0.0140, 0.0135, 0.0132, 0.0125, 0.0123]), 'labels': tensor([8, 8, 8, 8, 8, 8, 5, 5, 5, 5, 5, 5, 4, 4, 6, 3, 6, 3, 3, 4, 3, 4, 6, 6,\n",
      "        3, 3, 2, 8, 2, 4, 6, 6, 4, 2, 2, 1, 5, 4, 8, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "prediction = model.process_image('C:/Users/zack/Desktop/DuckNet_Data/Images_Test/DJI_20230105170403_0091_Z.JPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Train model</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import datasets module\n",
    "# from datasets import *\n",
    "file_path = 'basemodel.pt.zip'\n",
    "module = 'datasets'\n",
    "\n",
    "datasets = torch.package.PackageImporter(file_path).import_module(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = datasets.DetectionDataset(jpgfiles = 'C:/Users/zack/Desktop/DuckNet_Data/Images_Test/',\n",
    "                                           jsonfiles = 'C:/Users/zack/Desktop/DuckNet_Data/LabelMe_Annotations_Test/',\n",
    "                                           augment  = True,\n",
    "                                           negative_classes = [])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = sample_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# turn model.class_list into a dictionary\n",
    "label_dict = {i+1: model.class_list[i] for i in range(len(model.class_list))}\n",
    "\n",
    "# distinct colors \n",
    "distinct_colors = ['#f032e6', '#ffffff', '#ffe119', '#3cb44b', '#42d4f4',\n",
    "                    '#f58231', '#e6194B', '#dcbeff', '#469990', '#4363d8']\n",
    "\n",
    "# label color map for plotting color-coded boxes by class\n",
    "label_color_map = {k: distinct_colors[i] for i, k in enumerate(label_dict.keys())}\n",
    "\n",
    "# classes are values in label_dict\n",
    "classes = list(label_dict.values())\n",
    "\n",
    "# reverse label dictionary for mapping predictions to classes\n",
    "rev_label_dict = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# distinct colors \n",
    "distinct_colors = ['#f032e6', '#ffffff', '#ffe119', '#3cb44b', '#42d4f4',\n",
    "                    '#f58231', '#e6194B', '#dcbeff', '#469990', '#4363d8']\n",
    "\n",
    "# label color map for plotting color-coded boxes by class\n",
    "label_color_map = {k: distinct_colors[i] for i, k in enumerate(label_dict.keys())}\n",
    "\n",
    "# function for reshaping boxes \n",
    "def get_box(boxes):\n",
    "    boxes = np.array(boxes)\n",
    "    boxes = boxes.astype('float').reshape(-1, 4)\n",
    "    if boxes.shape[0] == 1 : return boxes\n",
    "    return np.squeeze(boxes)\n",
    "\n",
    "\n",
    "# function for plotting image\n",
    "def img_show(image, ax = None, figsize = (6, 9)):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize = figsize)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.imshow(image)\n",
    "    return ax\n",
    " \n",
    "\n",
    "def plot_bbox(ax, boxes, labels):\n",
    "    # add box to the image and use label_color_map to color-code by bounding box class if exists else 'black'\n",
    "    ax.add_patch(plt.Rectangle((boxes[:, 0], boxes[:, 1]), boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1],\n",
    "                    fill = False,\n",
    "                    color = label_color_map[labels.item()] if labels.item() in label_color_map else 'black', \n",
    "                    linewidth = 1.5))\n",
    "    # add label text to bounding box using label_dict if label exists else labels\n",
    "    ax.text(boxes[:, 2], boxes[:, 3], \n",
    "            (label_dict[labels.item()] if labels.item() in label_dict else None),\n",
    "            fontsize = 8,\n",
    "            bbox = dict(facecolor = 'white', alpha = 0.8, pad = 0, edgecolor = 'none'),\n",
    "            color = 'black')\n",
    "\n",
    "\n",
    "# function for plotting all boxes and labels on the image using get_polygon, img_show, and plot_mask functions\n",
    "def plot_detections(image, boxes, labels, ax = None):\n",
    "    ax = img_show(image.permute(1, 2, 0), ax = ax)\n",
    "    for i in range(len(boxes)):\n",
    "        box = get_box(boxes[i])\n",
    "        plot_bbox(ax, box, labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_detections(image, target['boxes'], target['labels']) # Sample anno data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataloader = datasets.create_dataloader(sample_dataset, batch_size = 16, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(sample_dataloader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the all samples from batch in a grid of subplots. \n",
    "plt.figure(figsize = (8, 32))\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(8, 2, 1 + i)\n",
    "    plot_detections(images[i], targets[i]['boxes'], targets[i]['labels'], ax = ax)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Sample {i + 1}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(file_path='basemodel.pt.zip', model_name='model')\n",
    "model.start_training_detector(imagefiles_train = 'C:/Users/zack/Desktop/DuckNet_Data/Images_Train/',\n",
    "                              jsonfiles_train = 'C:/Users/zack/Desktop/DuckNet_Data/LabelMe_Annotations_Train/',\n",
    "                              imagefiles_test = 'C:/Users/zack/Desktop/DuckNet_Data/Images_Test/',\n",
    "                              jsonfiles_test = 'C:/Users/zack/Desktop/DuckNet_Data/LabelMe_Annotations_Test/',\n",
    "                              negative_classes = [],\n",
    "                              epochs = 10,\n",
    "                              lr = 0.0001,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Converting Darwin JSON to LabelMe JSON </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json \n",
    "\n",
    "# def get_imagename_from_jsonfile(jsonfile):\n",
    "#     with open(jsonfile, 'r') as j:\n",
    "#         jsondata = json.loads(j.read())\n",
    "#     return jsondata['item']['slots'][0]['source_files'][0]['file_name']\n",
    "\n",
    "\n",
    "# def get_boxes_from_jsonfile(jsonfile):\n",
    "#     '''Reads bounding boxes from a DARWIN json file and returns them as a (Nx4) array'''\n",
    "#     with open(jsonfile, 'r') as j:\n",
    "#         jsondata = json.loads(j.read())\n",
    "        \n",
    "#     boxes = []\n",
    "#     for i in range(len(jsondata['annotations'])):\n",
    "#         box = [[jsondata['annotations'][i]['bounding_box']['x'], # xmin\n",
    "#                 jsondata['annotations'][i]['bounding_box']['y']], # ymin\n",
    "#                 [jsondata['annotations'][i]['bounding_box']['x']+jsondata['annotations'][i]['bounding_box']['w'], # xmax\n",
    "#                 jsondata['annotations'][i]['bounding_box']['y']+jsondata['annotations'][i]['bounding_box']['h']]] # ymax\n",
    "#         boxes.append(box)\n",
    "#     return boxes # return as (Nx4) array of bounding\n",
    "\n",
    "\n",
    "# def get_labels_from_jsonfile(jsonfile):\n",
    "#     '''Reads a list of labels in a DARWIN json file.'''\n",
    "#     with open(jsonfile, 'r') as j:\n",
    "#         jsondata = json.loads(j.read())\n",
    "#     return [ a['name'] for a in jsondata['annotations'] ]\n",
    " \n",
    "\n",
    "# def get_imagesize_from_jsonfile(jsonfile):\n",
    "#     with open(jsonfile, 'r') as j:\n",
    "#         jsondata = json.loads(j.read())\n",
    "#     return (jsondata['item']['slots'][0]['height'], jsondata['item']['slots'][0]['width'])\n",
    "\n",
    "\n",
    "# def darwin_to_labelme_json(jsondata):\n",
    "#     # convert darwin json to labelme json format. \n",
    "\n",
    "#     # labelme json should have following format:\n",
    "#     # {'version': '4.5.6',\n",
    "#     #  'flags': {},\n",
    "#     #  'shapes': [\n",
    "#     #      {\n",
    "#     #       'label': 'duck',\n",
    "#     #       'points': [[xmin, ymin], [xmax, ymax]],\n",
    "#     #       'group_id': null,\n",
    "#     #       'shape_type': 'rectangle',\n",
    "#     #       'flags': {}\n",
    "#     #      },\n",
    "#     #      ...\n",
    "#     #  ],\n",
    "#     # 'imagePath': 'path/to/image/file',\n",
    "#     # 'imageData': 'base64 encoded image data',\n",
    "#     # 'imageHeight': 480,\n",
    "#     # 'imageWidth': 640}\n",
    "\n",
    "#     # ignore the 'imageData' field. \n",
    "\n",
    "#     image_name = get_imagename_from_jsonfile(jsondata)\n",
    "#     boxes = get_boxes_from_jsonfile(jsondata)\n",
    "#     labels = get_labels_from_jsonfile(jsondata)\n",
    "#     image_size = get_imagesize_from_jsonfile(jsondata)\n",
    "\n",
    "#     shapes = []\n",
    "#     for i in range(len(labels)):\n",
    "#         shape = {'label': labels[i],\n",
    "#                     'points': boxes[i],\n",
    "#                     'group_id': 'null',\n",
    "#                     'shape_type': 'rectangle',\n",
    "#                     'flags': {}}\n",
    "#         shapes.append(shape)\n",
    "\n",
    "#     for i in range(len(labels)):\n",
    "#         labelme_json = {'version': '4.5.6',\n",
    "#                         'flags': {},\n",
    "#                         'shapes': shapes,\n",
    "#                         'imagePath': image_name,\n",
    "#                         'imageData': '',\n",
    "#                         'imageHeight': image_size[0],\n",
    "#                         'imageWidth': image_size[1]}\n",
    "#     return labelme_json\n",
    "\n",
    "# jsonfile = 'C:/Users/zack/Desktop/DuckNet_Data/Annotations_Test/DJI_20211215103949_0003_Z.json'\n",
    "# labelme_json = darwin_to_labelme_json(jsonfile)\n",
    "# labelme_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# dir = 'C:/Users/zack/Desktop/DuckNet_Data/'\n",
    "\n",
    "# # create two new folders in dir: LabelMe_Annotations_Test and LabelMe_Annotations_Train\n",
    "# os.makedirs(dir + 'LabelMe_Annotations_Test', exist_ok = True)\n",
    "# os.makedirs(dir + 'LabelMe_Annotations_Train', exist_ok = True)\n",
    "\n",
    "# # convert all json files in Annotations_Test to labelme json format and save them in LabelMe_Annotations_Test\n",
    "# for jsonfile in os.listdir(dir + 'Annotations_Test/'):\n",
    "#     labelme_json = darwin_to_labelme_json(dir + 'Annotations_Test/' + jsonfile)\n",
    "#     with open(dir + 'LabelMe_Annotations_Test/' + jsonfile, 'w') as j:\n",
    "#         json.dump(labelme_json, j)\n",
    "\n",
    "# # convert all json files in Annotations_Train to labelme json format and save them in LabelMe_Annotations_Train\n",
    "# for jsonfile in os.listdir(dir + 'Annotations_Train/'):\n",
    "#     labelme_json = darwin_to_labelme_json(dir + 'Annotations_Train/' + jsonfile)\n",
    "#     with open(dir + 'LabelMe_Annotations_Train/' + jsonfile, 'w') as j:\n",
    "#         json.dump(labelme_json, j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSD_PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
