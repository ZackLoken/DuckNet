{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda remove torchvision pytorch torchaudio -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install pytorch=2.0.1 torchvision=0.15.2 torchaudio pytorch::torchvision -c pytorch -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import PIL\n",
    "import pickle\n",
    "import importlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#internal modules\n",
    "MODULES = ['datasets', 'traininglib']\n",
    "\n",
    "\n",
    "from modellib import DuckDetector\n",
    "\n",
    "def save(self, destination):\n",
    "    from torch import package\n",
    "    if isinstance(destination, str):\n",
    "        destination = time.strftime(destination)\n",
    "        if not destination.endswith('.pt.zip'):\n",
    "            destination += '.pt.zip'\n",
    "\n",
    "    with package.PackageExporter(destination) as exp:\n",
    "        interns = [__name__.split('.')[-1]]+MODULES\n",
    "        exp.intern(interns)\n",
    "        exp.extern('**', exclude=['torchvision.**'])\n",
    "        externs = ['torchvision.ops.**', 'torchvision.datasets.**', 'torchvision.io.**']\n",
    "        exp.intern('torchvision.**', exclude=externs)\n",
    "        exp.extern(externs)\n",
    "        exp.intern('torchvision.models.detection.**')\n",
    "        # force inclusion of internal modules + re-save if importlib.reload'ed\n",
    "        for m in MODULES:\n",
    "            exp.save_module(m)\n",
    "        exp.save_module('modellib')\n",
    "        exp.save_pickle('model', 'model.pkl', self)\n",
    "        exp.save_text('model', 'class_list.txt', '\\n'.join(self.class_list))\n",
    "    return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_label_dict = {4.0: 'MALL', 1.0: 'AMCO', 3.0: 'GWTE', 6.0: 'NSHO', 2.0: 'GADW', 8.0: 'RNDU', 5.0: 'NOPI', 7.0: 'REDH'}\n",
    "\n",
    "basemodel_pt_zip = save(self=DuckDetector(classes_of_interest=[ # class order must match the label_dict from training\n",
    "                                    'Fulica americana',\n",
    "                                    'Mareca strepera',\n",
    "                                    'Anas carolinensis',\n",
    "                                    'Anas platyrhynchos',\n",
    "                                    'Anas acuta',\n",
    "                                    'Spatula clypeata',\n",
    "                                    'Aythya americana',\n",
    "                                    'Aythya collaris']), \n",
    "                                    destination=\"basemodel.pt.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = torch.package.PackageImporter(basemodel_pt_zip)\n",
    "print(imp.file_structure())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Test that packaged model opens</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_modelfile(file_path:str) -> \"torch.nn.Module\":\n",
    "        if file_path.endswith('.pt.zip'):\n",
    "            return torch.package.PackageImporter('basemodel.pt.zip').load_pickle('model', 'model.pkl', map_location='cpu')\n",
    "        elif file_path.endswith('.pkl'):\n",
    "            import pickle\n",
    "            return pickle.load(open('basemodel.pt.zip', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'basemodel.pt.zip'\n",
    "model = load_modelfile(file_path=file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Run model on sample images </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print predicts so that numbers don't have more than 4 decimal places\n",
    "# don't print with scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=4)\n",
    "prediction = model.process_image('C:/Users/zack/Desktop/DuckNet_Data_Test/Images/DJI_20221216101519_0005_Z.JPG')\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn model.class_list into a dictionary\n",
    "label_dict = {i+1: model.class_list[i] for i in range(len(model.class_list))}\n",
    "\n",
    "# distinct colors \n",
    "distinct_colors = ['#f032e6', '#ffffff', '#ffe119', '#3cb44b', '#42d4f4',\n",
    "                    '#f58231', '#e6194B', '#dcbeff', '#469990', '#4363d8']\n",
    "\n",
    "# label color map for plotting color-coded boxes by class\n",
    "label_color_map = {k: distinct_colors[i] for i, k in enumerate(label_dict.keys())}\n",
    "\n",
    "# function for reshaping boxes \n",
    "def get_box(boxes):\n",
    "    boxes = np.array(boxes)\n",
    "    boxes = boxes.astype('float').reshape(-1, 4)\n",
    "    if boxes.shape[0] == 1 : return boxes\n",
    "    return np.squeeze(boxes)\n",
    "\n",
    "\n",
    "# function for plotting image\n",
    "def img_show(image, ax = None, figsize = (6, 9)):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize = figsize)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.imshow(image)\n",
    "    return ax\n",
    "\n",
    "def plot_bbox_predicted(ax, boxes, labels, scores): # modify plot_bbox to add confidence scores\n",
    "    # add box to the image and use label_color_map to color-code by bounding box class if exists else 'black'\n",
    "    ax.add_patch(plt.Rectangle((boxes[:, 0], boxes[:, 1]), boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1],\n",
    "                    fill = False,\n",
    "                    color = label_color_map[labels.item()] if labels.item() in label_color_map else 'black', \n",
    "                    linewidth = 1.5))\n",
    "    \n",
    "    # add label and score to the bounding box. concatenate label and score to one string. \n",
    "    # use label_dict to replace class numbers with class names\n",
    "    ax.text(boxes[:, 0], boxes[:, 1] - 100,\n",
    "        s = f\"{label_dict[labels.item()]} {scores.item():.2f}\",\n",
    "        color = 'black',\n",
    "        fontsize = 6,\n",
    "        verticalalignment = 'top',\n",
    "        bbox = {'color': label_color_map[labels.item()] if labels.item() in label_color_map else 'black', 'pad': 0})\n",
    "    return ax\n",
    "\n",
    "\n",
    "# function for plotting all predictions on images\n",
    "def plot_predictions(image, boxes, labels, scores, ax = None):\n",
    "    ax = img_show(image, ax = ax)\n",
    "    for i in range(len(boxes)):\n",
    "        box = get_box(boxes[i])\n",
    "        plot_bbox_predicted(ax, box, labels[i], scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = model.load_image('C:/Users/zack/Desktop/DuckNet_Data_Test/Images/DJI_20221216101519_0005_Z.JPG')\n",
    "\n",
    "plot_predictions(image, \n",
    "                 prediction['boxes'], \n",
    "                 prediction['labels'], \n",
    "                 prediction['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.start_training_detector(imagefiles_train='C:/Users/zack/Desktop/DuckNet_Data_Test/Images/',\n",
    "                              jsonfiles_train='C:/Users/zack/Desktop/DuckNet_Data_Test/Annotations/',\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets module\n",
    "\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes = datasets.get_boxes_from_jsonfile('C:/Users/zack/Desktop/DuckNet_Data_Test/Annotations/DJI_20211215103949_0003_Z.json')\n",
    "# labels = datasets.get_labels_from_jsonfile('C:/Users/zack/Desktop/DuckNet_Data_Test/Annotations/DJI_20211215103949_0003_Z.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predictions(image, boxes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torchvision.models.detection.ssd300_vgg16()\n",
    "# model.load_state_dict(torch.load('C:/Users/zack/Documents/GitHub/SSD_VGG_PyTorch/ssd300_vgg16_gradientAccumulation_noHen.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict = {4.0: 'MALL', 1.0: 'AMCO', 3.0: 'GWTE', 6.0: 'NSHO', 2.0: 'GADW', 8.0: 'RNDU', 5.0: 'NOPI', 7.0: 'REDH'}\n",
    "\n",
    "# # distinct colors \n",
    "# distinct_colors = ['#f032e6', '#ffffff', '#ffe119', '#3cb44b', '#42d4f4',\n",
    "#                     '#f58231', '#e6194B', '#dcbeff', '#469990', '#4363d8']\n",
    "\n",
    "# # label color map for plotting color-coded boxes by class\n",
    "# label_color_map = {k: distinct_colors[i] for i, k in enumerate(label_dict.keys())}\n",
    "\n",
    "# # function for reshaping boxes \n",
    "# def get_box(boxes):\n",
    "#     boxes = np.array(boxes)\n",
    "#     boxes = boxes.astype('float').reshape(-1, 4)\n",
    "#     if boxes.shape[0] == 1 : return boxes\n",
    "#     return np.squeeze(boxes)\n",
    "\n",
    "\n",
    "# # function for plotting image\n",
    "# def img_show(image, ax = None, figsize = (6, 9)):\n",
    "#     if ax is None:\n",
    "#         fig, ax = plt.subplots(figsize = figsize)\n",
    "#     ax.xaxis.tick_top()\n",
    "#     ax.imshow(image)\n",
    "#     return ax\n",
    "\n",
    "# def plot_bbox_predicted(ax, boxes, labels, scores): # modify plot_bbox to add confidence scores\n",
    "#     # add box to the image and use label_color_map to color-code by bounding box class if exists else 'black'\n",
    "#     ax.add_patch(plt.Rectangle((boxes[:, 0], boxes[:, 1]), boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1],\n",
    "#                     fill = False,\n",
    "#                     color = label_color_map[labels.item()] if labels.item() in label_color_map else 'black', \n",
    "#                     linewidth = 1.5))\n",
    "    \n",
    "#     # add label and score to the bounding box. concatenate label and score to one string. \n",
    "#     # use label_dict to replace class numbers with class names\n",
    "#     ax.text(boxes[:, 0], boxes[:, 1] - 100,\n",
    "#         s = f\"{label_dict[labels.item()]} {scores.item():.2f}\",\n",
    "#         color = 'black',\n",
    "#         fontsize = 6,\n",
    "#         verticalalignment = 'top',\n",
    "#         bbox = {'color': label_color_map[labels.item()] if labels.item() in label_color_map else 'black', 'pad': 0})\n",
    "#     return ax\n",
    "\n",
    "\n",
    "# # function for plotting all predictions on images\n",
    "# def plot_predictions(image, boxes, labels, scores, ax = None):\n",
    "#     ax = img_show(image, ax = ax)\n",
    "#     for i in range(len(boxes)):\n",
    "#         box = get_box(boxes[i])\n",
    "#         plot_bbox_predicted(ax, box, labels[i], scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms.v2 as T\n",
    "\n",
    "# def run_model(model, image_path):\n",
    "#     # set model to evaluation\n",
    "#     model.eval()\n",
    "\n",
    "#     image = PIL.Image.open(image_path)\n",
    "    \n",
    "#     width, height = image.size\n",
    "\n",
    "#     # convert image to tensor\n",
    "#     image_tensor = T.ToImageTensor()(image)\n",
    "\n",
    "#     # # add batch dimension\n",
    "#     image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "#     image_tensor = T.ConvertImageDtype(torch.float32)(image_tensor)\n",
    "\n",
    "#     # resize to 300x300\n",
    "#     image_tensor = T.Resize((300, 300), antialias=True)(image_tensor)\n",
    "\n",
    "#     # normalize image\n",
    "#     image_tensor = T.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])(image_tensor)\n",
    "    \n",
    "#     # run model\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)\n",
    "\n",
    "#     # get boxes, labels, and scores\n",
    "#     boxes = output[0]['boxes']\n",
    "#     labels = output[0]['labels']\n",
    "#     scores = output[0]['scores']\n",
    "\n",
    "#     # filter out boxes with scores less than 0.5\n",
    "#     boxes = boxes[scores > 0.5]\n",
    "#     labels = labels[scores > 0.5]\n",
    "#     scores = scores[scores > 0.5]\n",
    "\n",
    "#     # rescale boxes to original image size\n",
    "#     boxes[:, 0] *= width / 300\n",
    "#     boxes[:, 1] *= height / 300\n",
    "#     boxes[:, 2] *= width / 300\n",
    "#     boxes[:, 3] *= height / 300\n",
    "\n",
    "#     # plot predictions\n",
    "#     plot_predictions(image, boxes, labels, scores)\n",
    "#     plt.show()\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = 'C:/Users/zack/Desktop/DuckNet_Data_Test/Images/DJI_20211215103949_0003_Z.JPG'\n",
    "# output = run_model(model, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(output))\n",
    "# print(type(output[0]))\n",
    "# print(type(output[0]['boxes']))\n",
    "# print(type(output[0]['labels']))\n",
    "# print(type(output[0]['scores']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSD_PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
